# Python Learning with Python. Second Edition

[toc]

## 1 什么是深度学习

### 1.1. 人工智能、机器学习和深度学习

$$深度学习\in 机器学习\in 人工智能$$

#### 1.1.1 人工智能

虽然许多基本理念在数年前就已经开始酝酿，但“人工智能”最终在1956年明确称为一个研究领域。当时达特茅斯学院年轻的数学系助理教授John McCarthy根据以下提案组织了一场夏季研讨会。

>该研究是基于以下猜想进行的：学习的各个方面或其他任何智能特征原则上都可以被精确描述，从而可以制造一台机器来模拟。我们将试图找到一种方法，让机器能够使用语言、形成抽象思维和概念、解决人类目前还不能解决的各种问题，并自我提升。我们认为，如果一组优秀的科学家在一起工作一个夏天，那么可以在其中一个或多个问题上取得重大进展。

夏天过去了，研讨会在结束时并没有完全解开它一开始打算研究的谜题。然而，许多参会者后来成为了这一领域的先驱，这次研讨也启动了一场延续至今的知识革命。

简而言之，人工智能可以被描述为试图将通常由人类完成的智力任务自动化。因此，人工智能是一个综合领域，不仅包括机器学习和深度学习，还包括更多不涉及学习的方法。直到20世纪80年代，大多数人工智能教科书中根本没有出现过“学习”二字。举个例子，早期的国际象棋程序仅涉及程序员手动编写的硬编码规则，，不能算作机器学习。事实上，在相当长的时间内，大多数专家相信，只要程序员手动编写足够多的明确规则来处理存储在显式数据库中的知识，就可以实现与人类水平相当的人工智能。这一方法被称为**符号主义人工智能**，从20世纪50年代到80年代末，它是人工智能的主流范式。在20世纪80年代的专家系统热潮中，这一方法的热度达到顶峰。

虽然符号主义人工智能适合用来解决定义明确的逻辑问题，比如下国际象棋，但它难以给出明确规则来解决更复杂、更模糊的问题，比如图像分类、语音识别或自然语言翻译。于是，一种替代符号主义人工智能的新方法出现了，这就是机器学习。

#### 1.1.2 机器学习

让计算机有效工作的常用方法是，由人类程序员编写规则，计算机遵循这些规则将输入数据转换为适当的答案。机器学习把这个过程反了过来：机器读取输入数据和相应的答案，然后找出应有的规则。机器学习系统是训练出来的，而不是明确地用程序写出来的。将与某些任务相关的许多示例输入机器学习系统，它会在这些示例中找到统计结构，从而最终找到将任务自动化的规则。

虽然在20世纪90年代才开始蓬勃发展，但机器学习已经循序成为人工智能最受欢迎且最成功的分支领域。这一发展趋势的驱动力来自速度更快的硬件与更大的数据集。机器学习与数理统计相关，但二者在在几个重要方面有所不同。与统计学相比，机器学习经常要处理复杂的大型数据集（比如包含数百万张图片的数据集，每张图片又包含数万像素），用经典的统计分析（比如贝叶斯分析）来处理这种数据集是不切实际的。因此，机器学习（尤其是深度学习）呈现出相对较少的数学理论（可能过于少了），从根本上来说是一门工程学科。

#### 1.1.3 从数据中学习规则与表示

为了给出深度学习的定义并搞清楚深度学习与其他机器学习方法的区别，我们首先需要了解机器学习算法在做什么。对于一项数据处理任务，给定预期输出的示例，机器学习系统可以发现执行任务的规则。即，我们需要已下3个要素来进行机器学习。

- 输入数据。
- 预期输出的示例
- 衡量算法效果的方法。这一衡量方法很有必要，其目的是计算算法的当前输出与与其输出之间的差距。衡量结果是一种反馈信号，用于调整算法的工作方式。这个调整步骤就是我们所说的**学习**。

机器学习模型将输入数据变换为更有意义的输出，这是一个从已知的输入输出示例中进行“学习”的过程。因此，机器学习和深度学习的核心问题在于**有意义地变换数据**，换句话说，在于学习输入数据的有用**表示**：这种表示可以让数据更接近预期输出。

什么是表示？这一概念的核心在于以一种不同的方式来查看数据。（表征数据或将数据编码）。举例来说，彩色图像可以编码为RGB（红、绿、蓝）格式或HSV格式（色相、饱和度、明度）格式，这些是对同一数据的两种表示。在处理某些任务时，使用某种表示可能会很困难，但换用另一种表示就会变得很简单。举个例子，对于“选择图像中所有的红色像素”这项任务，使用RGB格式会更简单，而对于“降低图像饱和度”这项任务，使用HSV格式则更简单。机器学习模型旨在为输入数据寻找合适的表示（对数据进行变换），使其更适合手头的任务。

对于简单的例子，利用人类智慧可以直接想出来适当的数据表示。但是如果任务更加复杂，比如对手写数字进行分类，难度会大很多。我们可以通过基于数字的规则（比如圆圈个数、垂直像素直方图和水平像素直方图）区分手写数字，但是手动寻找这样的有用表示是很困难的，而且可以想象，由此得到的基于规则的系统很脆弱，系统维护很困难。每当遇到一个新的手写数字不符合精心设计的规则是，你都不得不添加新的数据变换和新的规则，还要考虑它们与之前每条规则之间的相互作用。

这个过程能否自动化呢？

如果我们尝试系统地搜索自动生成的数据表示与基于这些表示的规则之间的不同组合，利用正确分类的数字所占百分比作为反馈信号，在某个开发数据集上找到那些好的组合，这样，我们做的就是机器学习。机器学习中的学习是指，寻找某种数据变换的自动搜索过程。

这种变换既可以是坐标变换，也可以是像素直方图和圆圈个数，还可以是线性投影、平移、非线性操作。机器学习算法在寻找这些变换时通常没有创造性，仅仅是遍历一组预先定义的操作，这组操作叫做假设空间。例如，所有可能的坐标变换组成的空间就是上述二维坐标分类示例的假设空间。

简而言之，机器学习就是指在预先定义的假设空间中，利用反馈信号的指引，在输入数据中寻找有用的表示和规则。

#### 1.1.4 深度学习之“深度”

深度学习是机器学习的一个分支领域：它是从数据中学习表示的一种新方法，强调从连续的层中学习，这些层对应于越来越有意义的表示。深度学习之“深度”并不是说这种方法能够获取更深层次的理解，而是指一系列连续的表示层。数据模型所包含的层数被称为该模型的深度。这一领域的其他名称还有分类表示学习（layered representations learning）和层级表示学习（hierarchical representations learning）。现代深度学习模型通常包含数十个甚至上百个连续的表示层，它们都是从训练数据中自动学习而来的。与之相对，其他机器学习方法的重点通常仅学习一两层的数据表示（例如获取像素直方图，然后应用分类规则），因此有时也被成为浅层学习。

在深度学习中，这些分层表示是通过叫做神经网络（neural network）的模型学习得到的。神经网络的结构是逐层堆叠。神经网络这一术语来自神经生物学，然而，深度学习模型并不是大脑模型。没有证据表明大脑的学习机制与现代深度歇息模型的学习机制相同。

深度学习算法学到的数据表示是什么样的呢？我们来看一个深度神经网络如何对数字图像进行变换，以便识别图像中的数字。

这个神经网络将数字图像变换为与原始图像差别越来越大的表示，而其中关于最终结果的信息越来越丰富。可以将深度神经网络看作多级信息蒸馏（information distillation）过程：信息穿过连续的过滤器，其纯度越来越高（对任务的帮助越来越大）。

#### 1.1.5 用三张图理解深度学习的工作原理

在神经网络中，每层对输入数据所作的具体操作保存在该层的权重中，权重实质就是一串数字。用术语来讲，每层实现的变换由其权重来参数化。权重又是也被成为该层的参数（parameter）。在这种语境下，学习的意思就是为神经网络的所有层找到一组权重值，使得该神经网络能够将每个示例的输入与其目标正确地一一对应。但问题来了：一个深度神经网络可能包含上千万个参数，找到其中所有参数的正确取值似乎是一项非常艰巨的任务，特别是考虑到修改一个参数将影响其他所有参数的行为。

若要控制某个事物，首先需要能够观察它。若要控制神经网络的输出，需要能够衡量该项输出与预期结果之间的距离。这是神经网络损失函数（loss function）的任务，该函数有时也被称为目标函数（objective function）或代价函数（cost function）。损失函数的输入是神经网络的预测值与真实目标值，输出是一个距离值，反应该神经网络在这个示例上的效果好坏。

深度学习的基本技巧是将损失值作为反馈信号，来对权重进行微调，以降低当前示例对应的损失值。这种调节是优化器（optimizer）的任务，它实现了所谓的反向传播（backpropagation）算法，这是深度学习的核心算法。

由于一开始对神经网络的权重进行随机赋值，因此神经网络仅实现了一系列随即变换，其输出值自然与理想结果相去甚远，相应地，损失值也很大。但是，神经网络每处理一个示例，权重值都会向着正确的方向微调，损失值也相应减小。这就是训练循环（traning loop），将这种循环重复足够多的次数（通常是对数千个示例进行数十次迭代），得到的权重值可以使损失函数最小化。具有最小损失值的神经网络，其输出值与目标值尽可能地接近，这就是一个训练好的神经网络。

#### 1.1.6 深度学习已经取得的进展

- 接近人类水平的图像分类
- 接近人类水平的语音识别
- 接近人类水平的手写文字识别
- 大幅改进的机器翻译
- 大幅改进的文本到语音转换
- 数字助理
- 接近人类水平的自动驾驶
- 更好的广告定向投放
- 更好的互联网搜索结果
- 能够回答用自然语言提出的问题
- 在下围棋时能战胜人类

随着每一个里程碑的出现，我们越来越接近这样一个时代：深度学习在人类从事的每一项活动和每一个领域中都能为我们提供帮助，包括科学、医学、制造业、能源、交通、软件开发、农业，甚至是艺术创作。

#### 1.1.7 不要相信短期炒作

虽然深度学习近年来取得了令人瞩目的成就，但人们对这一领域在未来十年里所能取得的成就似乎期望过高。虽然一些改变世界的应用（比如自动驾驶汽车）已经触手可及，但更多的应用可能在很长一段时间内难以实现，比如可信的对话系统、达到人类水平的跨任意语言的机器翻译，以及达到人类水平的自然语言理解。

#### 1.1.8 人工智能的未来

不要相信短期炒作，但一定要相信长期愿景。人工智能或许需要一段时间才能充分发挥其潜力，这一潜力大到难以想象，但人工智能时代终将到来，它将以一种奇妙的方式改变我们的世界。

### 1.2 深度学习之前：机器学习简史

当前工业界所使用的大部分机器学习算法并不是深度学习算法。深度学习并不一定总是解决问题的正确工具：有时没有足够的数据，深度学习不适用；有时用其他算法可以更好的解决问题。

关于机器学习方法的详细讨论已经超出了本书的范围，但我们将简要回顾这些方法，并了解这些方法发展的历史背景。这样，我们便可以将深度学习放入机器学习的大背景中，更好地理解深度歇息的起源和重要性。

#### 1.2.1 概率建模

概率建模（probabilistic modeling）是统计学原理在数据分析中的应用。它是最早的机器学习形式之一，至今仍在广泛使用。在概率建模中，最著名的算法就是朴素贝叶斯算法。

朴素贝叶斯是一类机器学习分类器，基于对贝叶斯定理的应用。它假设输入数据的特征都是独立的（这是一个很强的假设，或者说是“朴素”的假设，其名称正来源于此）。这种数据分析方法比计算机出现的还要早，在其第一次被计算机实现的几十年前就已经靠人工计算来应用了。

另一个密切相关的模型是logistic回归（logistic regression，简称logreg），它有时被认为是现代机器学习的“Hello World”。不要被它的名称所误导：logreg是一种分类算法，而不是回归算法。与朴素贝叶斯类似，logreg的出现也比计算机早很长时间，但由于它既简单又通用，因此至今仍然很有用。

#### 1.2.2 早期神经网络

神经网络的早期版本已经完全被本章介绍的现代版本所取代，但仍有助于我们了解深度学习的起源。虽然人们早在20实际50年代就开始研究神经网络及其核心思想，但这一方法在数十年后才被人们所使用。在很长一段时间里，一直没有训练大型神经网络的有效方法。这种情况在20世纪80年代中期发生了变化，当时有很多人独立地重新发现了反向传播算法，一种利用梯度下降优化来训练一系列参数化运算链的方法，并开始将其应用于神经网络。

神经网络的第一个成功的实际应用来自于1989年的贝尔实验室，当时Yann LeCun将卷积神经网络的早期思想与反向传播算法相结合，并将其应用于手写数字分类问题。

#### 1.2.3 核方法

神经网络取得了第一次成功，但一种新的机器学习方法在这时声名鹊起，这种方法就是核方法。核方法（kernel method）是一组分类算法，其中最有名的就是支持向量机（support vector machine, SVM）。

SVM的原理是寻找划分两个类别的决策边界。SVM通过以下两步来寻找决策边界：

（1）将数据映射到新的高维表示，此时决策边界可以用一个超平面来表示。

（2）尽量让超平面与每个类别最近的数据点之间的距离最大化，从而计算出良好的决策边界（分离超平面）。这样一来，决策边界便可以很好地推广到训练数据集之外的新样本。

将数据映射到高维表示从而使分类问题简化，这一方法可能听起来不错，但实际上计算起来很棘手。这是就需要用到核技巧（kernel trick）。核技巧的基本思想是：要在新的表示空间中找到良好的决策超平面，不需要直接计算点在新空间中的坐标，只需要计算在新空间中点与点之间的距离，而利用核函数可以高效地完成这种计算。核函数是一个在计算上容易实现的运算，它将初始空间中的任意两点映射为这两点在目标空间中的距离，从而完全避免了直接计算新的表示。核函数通常是认为选择的，而不是从数据中学到的。对于SVM来说，只有分离超平面是通过学习得到的。

SVM刚刚出现时，在简单的分类问题上表现出非常好的性能。当时只有少数机器学习方法得到大量的理论支持，并且经得起严谨的数学分析，非常易于理解核解释，SVM就是其中之一。由于SVM具有这些有用的性质，因此它在很长一段时间里非常流行。

但事实证明，SVM很难扩展到大型数据集，并且在图像分类等感知问题上的效果也不好。SVM是一种浅层方法，因此要将其应用于感知问题，首先需要手动提取出最有用的表示（这一步骤叫做特征工程）。这一步骤很难，而且不稳定。如果想用SVM来进行手写数字分类，那么不能从原始像素开始，而应该首先手动找到有用的表示（比如像素直方图），使问题变得更易于处理。

#### 1.2.4 决策树、随机森林核梯度提升机

决策树（decision tree）是类似于流程图的结构，可以对输入数据进行分类或根据输入预测输出值。
